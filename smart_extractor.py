import re
import json
from transformers import pipeline
from typing import Dict, Any


class SmartDataExtractor:
    def __init__(self):
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞...")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        self.ai_helper = pipeline(
            "text-generation",
            model="inkoziev/rugpt_chitchat",
            device_map="auto"
        )

    def extract_inn_and_name(self, text: str) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç: {text}")

        # 1. Rule-based –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ (–Ω–∞–¥–µ–∂–Ω–æ)
        rule_based_result = self._rule_based_extraction(text)

        # 2. –ï—Å–ª–∏ rule-based –Ω–µ –Ω–∞—à–µ–ª –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º AI
        if not rule_based_result["–ò–ù–ù"] or not rule_based_result["–§–ò–û"]:
            print("‚ö†Ô∏è  Rule-based –Ω–µ –Ω–∞—à–µ–ª –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ–¥–∫–ª—é—á–∞–µ–º AI...")
            ai_result = self._ai_assisted_extraction(text, rule_based_result)
            return ai_result

        print("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã rule-based –º–µ—Ç–æ–¥–æ–º")
        return rule_based_result

    def _rule_based_extraction(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º"""
        result = {
            "–ò–ù–ù": None,
            "–§–ò–û": None,
            "–º–µ—Ç–æ–¥": "rule-based",
            "–∏—Å—Ö–æ–¥–Ω—ã–π_—Ç–µ–∫—Å—Ç": text
        }

        # –ò—â–µ–º –ò–ù–ù (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã, –¥–ª–∏–Ω–∞ 10 –∏–ª–∏ 12)
        inn_matches = re.findall(r'\b\d{10,12}\b', text)
        if inn_matches:
            for inn in inn_matches:
                if len(inn) in [10, 12]:
                    result["–ò–ù–ù"] = inn
                    break

        # –ò—â–µ–º –§–ò–û (3 —Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏)
        fio_patterns = [
            r'\b([–ê-–Ø–Å][–∞-—è—ë]+)\s+([–ê-–Ø–Å][–∞-—è—ë]+)\s+([–ê-–Ø–Å][–∞-—è—ë]+)\b',  # –§ –ò –û
            r'\b([–ê-–Ø–Å][–∞-—è—ë]+)\s+([–ê-–Ø–Å][–∞-—è—ë]+)\b',  # –§ –ò
        ]

        for pattern in fio_patterns:
            match = re.search(pattern, text)
            if match:
                result["–§–ò–û"] = " ".join(match.groups())
                break

        return result

    def _ai_assisted_extraction(self, text: str, rule_result: Dict) -> Dict[str, Any]:
        """AI-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"""
        prompt = f"""
        –¢–ï–ö–°–¢: "{text}"

        –£–∂–µ –Ω–∞–π–¥–µ–Ω–æ rule-based –º–µ—Ç–æ–¥–æ–º:
        - –ò–ù–ù: {rule_result['–ò–ù–ù'] or '–Ω–µ –Ω–∞–π–¥–µ–Ω'}
        - –§–ò–û: {rule_result['–§–ò–û'] or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}

        –ü–æ–º–æ–≥–∏ –Ω–∞–π—Ç–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
        –ò–ù–ù: <–Ω–∞–π–¥–µ–Ω–Ω—ã–π_–∏–Ω–Ω_–∏–ª–∏_–ø—É—Å—Ç–æ>
        –§–ò–û: <–Ω–∞–π–¥–µ–Ω–Ω–æ–µ_—Ñ–∏–æ_–∏–ª–∏_–ø—É—Å—Ç–æ>
        """

        try:
            response = self.ai_helper(
                prompt,
                max_new_tokens=100,
                num_return_sequences=1
            )[0]['generated_text']

            # –ü–∞—Ä—Å–∏–º AI –æ—Ç–≤–µ—Ç
            ai_inn = self._extract_ai_value(response, "–ò–ù–ù")
            ai_fio = self._extract_ai_value(response, "–§–ò–û")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å rule-based —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            final_result = rule_result.copy()
            final_result["–º–µ—Ç–æ–¥"] = "hybrid"

            if not final_result["–ò–ù–ù"] and ai_inn:
                final_result["–ò–ù–ù"] = ai_inn
                final_result["AI_–ø–æ–º–æ—â—å_–ò–ù–ù"] = True

            if not final_result["–§–ò–û"] and ai_fio:
                final_result["–§–ò–û"] = ai_fio
                final_result["AI_–ø–æ–º–æ—â—å_–§–ò–û"] = True

            return final_result

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ AI: {e}")
            return rule_result

    def _extract_ai_value(self, response: str, field: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ AI –æ—Ç–≤–µ—Ç–∞"""
        pattern = f"{field}:\s*(.+)"
        match = re.search(pattern, response)
        if match:
            value = match.group(1).strip()
            # –û—á–∏—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
            if value.lower() in ['–Ω–µ –Ω–∞–π–¥–µ–Ω', '–ø—É—Å—Ç–æ', 'none', '']:
                return None
            return value
        return None


def main():
    extractor = SmartDataExtractor()

    print("ü§ñ –£–º–Ω—ã–π –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 50)

    test_texts = [
        "–ê–∫–∫—Ä n 123, –ò–Ω–Ω 4353229845, –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
        "–ö–ª–∏–µ–Ω—Ç: –ü–µ—Ç—Ä–æ–≤ –ê–ª–µ–∫—Å–µ–π –°–µ—Ä–≥–µ–µ–≤–∏—á, –ò–ù–ù 123456789012",
        "–§–ò–û: –°–∏–¥–æ—Ä–æ–≤–∞ –ú–∞—Ä–∏—è, –∏–Ω–Ω 9876543210",
        "–ü—Ä–æ—Å—Ç–æ –∫–∞–∫–æ–π-—Ç–æ —Ç–µ–∫—Å—Ç –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö",
        "–ò–ù–ù 1111111111 –∏ –∏–º—è John Doe",  # –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ –∏–º—è
    ]

    for i, text in enumerate(test_texts, 1):
        print(f"\n{'=' * 60}")
        print(f"–¢–ï–°–¢ {i}: {text}")
        print('=' * 60)

        result = extractor.extract_inn_and_name(text)

        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()